import whisper
from transformers import MarianMTModel, MarianTokenizer, pipeline
import os

# ğŸŒ Define available local translation models
language_models = {
    "ur": "huggingface_model_ur",
    "fr": "huggingface_model_fr",
    "ps": "huggingface_model_ps"
}

# ğŸ“¥ Ask user which language they want
print("Available language codes:")
for code in language_models:
    print(f"  â¤ {code}")
target_lang = input("Enter language code (e.g., ur, fr, ps): ").strip().lower()

# ğŸ“ Paths
base_dir = os.path.dirname(__file__)
audio_path = os.path.join(base_dir, "sample.opus")

# âœ… Check if audio file exists
if not os.path.exists(audio_path):
    raise FileNotFoundError("sample.opus not found in this folder.")

# âœ… Check if language model is available
if target_lang not in language_models:
    raise ValueError(f"Model for '{target_lang}' not found. Available: {', '.join(language_models.keys())}")

model_path = os.path.join(base_dir, language_models[target_lang])
if not os.path.exists(model_path):
    raise FileNotFoundError(f"Local model folder not found at: {model_path}")

# ğŸ™ï¸ Step 1: Transcribe
print("ğŸ™ï¸ Transcribing to English...")
whisper_model = whisper.load_model("base")
result = whisper_model.transcribe(audio_path)
original_text = result["text"]
print("ğŸ—£ï¸ Transcribed Text:", original_text)

# ğŸŒ Step 2: Translate
print(f"ğŸ”„ Translating to {target_lang}...")
tokenizer = MarianTokenizer.from_pretrained(model_path)
translation_model = MarianMTModel.from_pretrained(model_path)
translator = pipeline("translation", model=translation_model, tokenizer=tokenizer)
translated = translator(original_text)[0]["translation_text"]
print(f"ğŸŒ Translated Text ({target_lang}):", translated)

# ğŸ’¾ Step 3: Save translation
output_path = os.path.join(base_dir, f"translated_{target_lang}.txt")
with open(output_path, "w", encoding="utf-8") as f:
    f.write(translated)
print(f"âœ… Translation saved to: {output_path}")
