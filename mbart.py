# -*- coding: utf-8 -*-
"""mBart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19TepNAmTeU0kAZnYP-py2I3XB8dHMEBq
"""

pip install transformers torch sentencepiece

pip install protobuf

from transformers import MBartForConditionalGeneration, MBart50TokenizerFast

# Load the mBART50 model and tokenizer
model_name = "facebook/mbart-large-50-many-to-many-mmt"
tokenizer = MBart50TokenizerFast.from_pretrained(model_name)
model = MBartForConditionalGeneration.from_pretrained(model_name)

# Input text and language codes
text = "Hello, how are you?"

# Set source and target languages
tokenizer.src_lang = "en_XX"  # English
encoded = tokenizer(text, return_tensors="pt")

# Generate translation
generated_tokens = model.generate(
    **encoded,
    forced_bos_token_id=tokenizer.lang_code_to_id["ur_PK"]  # Urdu
)

# Decode the output
output = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(output)

from transformers import MBartForConditionalGeneration, MBart50TokenizerFast

# Load the mBART50 model and tokenizer
model_name = "facebook/mbart-large-50-many-to-many-mmt"
tokenizer = MBart50TokenizerFast.from_pretrained(model_name)
model = MBartForConditionalGeneration.from_pretrained(model_name)

# Input text and language codes
text = "hé, qu'est-ce qu'il y a ?"

# Set source and target languages
tokenizer.src_lang = "fr_XX"
encoded = tokenizer(text, return_tensors="pt")

# Generate translation
generated_tokens = model.generate(
    **encoded,
    forced_bos_token_id=tokenizer.lang_code_to_id["ur_PK"]  # Urdu
)

# Decode the output
output = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(output)

from transformers import MBartForConditionalGeneration, MBart50TokenizerFast

# Load the mBART50 model and tokenizer
model_name = "facebook/mbart-large-50-many-to-many-mmt"
tokenizer = MBart50TokenizerFast.from_pretrained(model_name)
model = MBartForConditionalGeneration.from_pretrained(model_name)

# Input text and language codes
text = "آپ کیسے ہیں"

# Set source and target languages
tokenizer.src_lang = "ur_PK"
encoded = tokenizer(text, return_tensors="pt")

# Generate translation
generated_tokens = model.generate(
    **encoded,
    forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"]  # Urdu
)

# Decode the output
output = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(output)

!pip install ffmpeg-python

import os
# Add your actual FFmpeg bin path here
import whisper
model = whisper.load_model("base")

# Transcribe file
result = model.transcribe("harvard.wav")
text = result["text"]
print("Transcription:", text)

from transformers import MarianMTModel, MarianTokenizer

model_name = 'Helsinki-NLP/opus-mt-en-ur'

tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)

tokens = tokenizer(text, return_tensors="pt", padding=True)
translated = model.generate(**tokens)

output = tokenizer.decode(translated[0], skip_special_tokens=True)
print("After translation:\n", output)

with open("translationnur.txt", "w", encoding="utf-8") as f:
    f.write(output)

print("Translation saved to translationnur.txt")

!pip install git+https://github.com/openai/whisper.git
!pip install transformers
!pip install sentencepiece
!pip install ffmpeg-python

import os
# Add your actual FFmpeg bin path here
import whisper
model = whisper.load_model("base")

# Transcribe file
result = model.transcribe("harvard.wav")
text = result["text"]
print("Transcription:", text)

from transformers import MarianMTModel, MarianTokenizer

model_name = 'Helsinki-NLP/opus-mt-en-ur'

tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)

tokens = tokenizer(text, return_tensors="pt", padding=True)
translated = model.generate(**tokens)

output = tokenizer.decode(translated[0], skip_special_tokens=True)
print("After translation:\n", output)

with open("translationnur.txt", "w", encoding="utf-8") as f:
    f.write(output)

print("Translation saved to translationnur.txt")