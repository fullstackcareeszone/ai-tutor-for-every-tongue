#  AI Tutor for Every Tongue

An intelligent multilingual tutor that listens to your spoken input, transcribes it using speech-to-text, translates it into the desired language, answers your questions using NLP models, and reads responses out loud using text-to-speech.

---

## ðŸš€ Features

- ðŸŽ¤ **Speech-to-Text (STT)**: Converts spoken audio into text using OpenAI Whisper.
- ðŸŒ **Translation**: Translates English text into multiple languages using Hugging Face models (MBART, MarianMT).
- â“ **Question Answering (Q&A)**: Answers user questions using pre-trained Transformer models.
- ðŸ”Š **Text-to-Speech (TTS)**: Speaks answers out loud using Coqui TTS or Tacotron.

---

## ðŸ› ï¸ Tech Stack

| Component           | Library/Model                          |
|--------------------|----------------------------------------|
| Speech-to-Text     | `openai-whisper`                       |
| Translation        | `transformers` (MBART / MarianMT)      |
| Question Answering | `transformers` (e.g., BERT-based QA)   |
| Text-to-Speech     | `TTS` (by Coqui) or `pyttsx3`          |

##  ðŸ Install Dependencies
pip install openai-whisper
pip install transformers
pip install sentencepiece
pip install soundfile
pip install TTS   # For Coqui TTS
pip install pyttsx3

## ðŸ§  Models Used
openai/whisper-base

facebook/mbart-large-50-many-to-many-mmt

Helsinki-NLP/opus-mt-en-ur and other MarianMT variants

deepset/bert-base-cased-squad2 for Q&A

tts_models/en/ljspeech/tacotron2-DDC (for TTS)


---

## ðŸ“‚ Project Structure

ai-tutor-for-every-tongue/
â”‚
â”œâ”€â”€ day01-project/                 # Day 01: STT (Whisper) + Translation (Basic)
â”‚   â”œâ”€â”€ sample.opus               # Sample audio file
â”‚   â”œâ”€â”€ transcribe.py             # Whisper-based audio transcription
â”‚   â”œâ”€â”€ translated_pa.txt         # Translated output (Pashto)
â”‚
â”œâ”€â”€ day02-project/                 # Day 02: Translation Pipeline
â”‚   â”œâ”€â”€ huggingface_models/       # Hugging Face model assets (cached or custom)
â”‚   â”œâ”€â”€ mbart_translate.py        # MBART-based translation script
â”‚   â”œâ”€â”€ translate_pipeline.py     # Full audio â†’ translated text pipeline
â”‚   â”œâ”€â”€ sample.opus               # Another test audio file
â”‚   â”œâ”€â”€ translated_ur.txt         # Urdu translation output
â”‚
â”œâ”€â”€ day03-project/                 # Day 03: Q&A + TTS
â”‚   â”œâ”€â”€ mbart.py                  # Alternate or extended MBART translator
â”‚   â”œâ”€â”€ QA.py                     # Question Answering using Hugging Face
â”‚   â”œâ”€â”€ tts_02.py                 # TTS implementation (likely alternate)
â”‚   â”œâ”€â”€ TTS.py                    # Main TTS script (Coqui / pyttsx3)
â”‚
â”œâ”€â”€ tts_env/                      # TTS-specific virtual environment
â”‚
â”œâ”€â”€ venv/                         # General project virtual environment
â”‚

> **Branch:** `khansauro0j`  
> **Contributor:** Khansa Urooj  
> **Date:** July 11, 2025 (Day 01)
> ** email:** khansaurooj912@example.com
